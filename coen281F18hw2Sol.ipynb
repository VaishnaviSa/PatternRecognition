{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2  (Due: 10/15/2018)\n",
    "\n",
    "COEN 281, Fall 2018  \n",
    "Professor Marwah\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this HW is to implement k-NN and cross-validation to find the best value of $k$ for a binary classification task. The task to diagnose breast cancer based on 30 numeric features. However, to keep things simple, we will only use two of those features. The output is binary: 0 benign, 1 malignant. In all there are 569 examples, which we will split into training and test sets. There are no missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "dat = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(dat.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "print(dat.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer Wisconsin (Diagnostic) Database\n",
      "=============================================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "References\n",
      "----------\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment the following and run it to get a description of the data set\n",
    "print(dat.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dat is a dictionary with the data, let's see what keys it has\n",
    "dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "print(dat.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dat.data, columns=dat.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# we will use two features: 'mean area' and 'mean concave points'\n",
    "ix1 = np.where(dat[\"feature_names\"] == \"mean area\")[0][0]\n",
    "ix2 = np.where(dat[\"feature_names\"] == \"mean concave points\")[0][0]\n",
    "print(ix1)\n",
    "print(ix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_cells():    \n",
    "    plt.scatter(dat[\"data\"][:,ix1][dat[\"target\"]==1], dat[\"data\"][:,ix2][dat[\"target\"]==1], marker='x', color='C0')\n",
    "    plt.scatter(dat[\"data\"][:,ix1][dat[\"target\"]==0], dat[\"data\"][:,ix2][dat[\"target\"]==0], marker='+', color='C3')\n",
    "    plt.xlim([0,2600])\n",
    "    plt.ylim([0,0.21])\n",
    "    plt.xlabel(\"Mean Area\")\n",
    "    plt.ylabel(\"Mean Concave Points\")\n",
    "    plt.legend(['Benign', 'Malignant'])\n",
    "plot_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 2) (569,)\n",
      "Number of points: 569\n",
      "range (min, max), X1: (143.50, 2501.00), X2: (0.00, 0.20)\n",
      "mean: 654.89, 0.05\n",
      "variance: 123843.55, 0.001506\n",
      "(array([143.5,   0. ]), array([2.501e+03, 2.012e-01]))\n",
      "Number of points: 569\n",
      "range (min, max), X1: (0.00, 1.00), X2: (0.00, 1.00)\n",
      "mean: 0.22, 0.24\n",
      "variance: 0.02, 0.037194\n"
     ]
    }
   ],
   "source": [
    "X = dat[\"data\"][:,(ix1,ix2)]\n",
    "Y = dat[\"target\"]\n",
    "\n",
    "# verify shape of X and Y\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# stats of the two features\n",
    "from scipy import stats\n",
    "st = stats.describe(X)\n",
    "print(\"Number of points: %i\" % st.nobs)\n",
    "print(\"range (min, max), X1: (%.2f, %.2f), X2: (%.2f, %.2f)\" % (st.minmax[0][0], st.minmax[1][0], st.minmax[0][1], st.minmax[1][1]))\n",
    "print(\"mean: %.2f, %.2f\" % (st.mean[0], st.mean[1]))\n",
    "print(\"variance: %.2f, %f\" % (st.variance[0], st.variance[1]))\n",
    "# Given the stats, is it a good idea to normalize the features?\n",
    "#yes. We have to normalize.For given  features mean area and  mean concave points x=[2501.00,0.20]\n",
    "#is skewed towards (mean area). so we should normalize.\n",
    "# add code to normalize features\n",
    "def normalizeData(X, normalize_cols):\n",
    "    \"\"\" Normalize specified columns of X to range [0,1] in place. \"\"\"\n",
    "    min_X = X[:,normalize_cols].min(axis=0)\n",
    "    max_X = X[:,normalize_cols].max(axis=0)\n",
    "    X[:,normalize_cols] = (X[:,normalize_cols] - min_X) / (max_X - min_X)\n",
    "    return min_X, max_X\n",
    "ranges = normalizeData(X, [True, True])\n",
    "\n",
    "print(ranges)\n",
    "st = stats.describe(X)\n",
    "print(\"Number of points: %i\" % st.nobs)\n",
    "print(\"range (min, max), X1: (%.2f, %.2f), X2: (%.2f, %.2f)\" % (st.minmax[0][0], st.minmax[1][0], st.minmax[0][1], st.minmax[1][1]))\n",
    "print(\"mean: %.2f, %.2f\" % (st.mean[0], st.mean[1]))\n",
    "print(\"variance: %.2f, %f\" % (st.variance[0], st.variance[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 2) (398,) (171, 2) (171,)\n"
     ]
    }
   ],
   "source": [
    "# split into training set / test set\n",
    "#\n",
    "# usually you would do the split randomly; here for deterministic results, we assume the data \n",
    "# points are already shuffled and take the first 70% as training and the rest as test\n",
    "#\n",
    "nTot = X.shape[0]\n",
    "nTr = int(nTot*0.7)\n",
    "nTs = nTot - nTr\n",
    "\n",
    "Xtr = X[0:nTr,]\n",
    "Ytr = Y[0:nTr]\n",
    "\n",
    "Xts = X[nTr:nTot,]\n",
    "Yts = Y[nTr:nTot,]\n",
    "\n",
    "# verify shapes\n",
    "print(Xtr.shape, Ytr.shape, Xts.shape, Yts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the following functions for k-NN\n",
    "# input: Xtr - training examples input features, size nXd\n",
    "#        Ytr - label (can assume to be binary 0/1), size nX1\n",
    "#        Xts - test examples input features, for which labels (Yts) \n",
    "#              need to be predicted, size mXd\n",
    "#        k   - k for the k-NN algo \n",
    "#\n",
    "# output: Yts - 0/1 labes for Xts, size mX1\n",
    "#\n",
    "#  This function predicts the binary labels for Xts, given the training\n",
    "#  data Xtr, Ytr and k, using the k-NN algorithm\n",
    "#\n",
    "def knn_predict(Xtr, Ytr, Xts, k):\n",
    "    # compute in two steps\n",
    "    \n",
    "    # step 1: compute dist matrix between Xts and Xtr\n",
    "    #\n",
    "    dist = compute_dist_mat(Xts, Xtr)\n",
    "    #dist.shape=171x398\n",
    "    #print(dist.shape)\n",
    "    # step 2: use the dist matrix and use k-nn to find labels for Xts \n",
    "    # hint: function numpy.argsort may be useful\n",
    "    # in case of a tie, pick a class randomly\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    testShape = dist.shape[0]\n",
    "    #testShape=171\n",
    "    #print(testShape)\n",
    "    yPrediction = np.zeros(testShape)\n",
    "    for i in range(testShape):\n",
    "        K_closest_y_5 = []\n",
    "        #dist[i].shape=398\n",
    "        #print(dist[i].shape)\n",
    "        closestIndex_5 = np.argsort(dist[i])[:k]\n",
    "        #closestIndex_5.shape=5\n",
    "        #print(closestIndex_5.shape)\n",
    "        K_closest_y_5 = Ytr[closestIndex_5]\n",
    "        #print(K_closest_y_5)\n",
    "        #bincount Count number of occurrences of each value in array\n",
    "        #print(np.bincount(K_closest_y_5))\n",
    "        #np.argmax Returns the indices of the maximum values along an axis\n",
    "        yPrediction[i] = np.argmax(np.bincount(K_closest_y_5))\n",
    "        #yPrediction.shape=171\n",
    "    #print(yPrediction)\n",
    "    return(yPrediction)\n",
    "\n",
    "#  compute_dist_mat(Xts, Xtr)\n",
    "#\n",
    "#  input: Xts - test examples, size mXd\n",
    "#         Xtr - training examples, size nXd\n",
    "#  output: L2 distance matrix mXn\n",
    "#\n",
    "#   if Xts is mXd, and Xtr is nXd, this function returns a matrix of size mXn with the L2 distances; the (i,j) \n",
    "#     entry of the matrix is the L2 distance between ith test and jth training example \n",
    "#\n",
    "def compute_dist_mat(Xts, Xtr):\n",
    "    # use two for loops to compute the matrix\n",
    "    # YOUR CODE HERE\n",
    "    testShape = Xts.shape[0]\n",
    "    trainShape = Xtr.shape[0]\n",
    "    dist = np.zeros((testShape, trainShape))\n",
    "    for i in range(testShape):\n",
    "        for j in range(trainShape):\n",
    "            dist[i, j] = np.sqrt(np.sum((Xts[i]-Xtr[j])**2))\n",
    "    #print(dist.shape)        \n",
    "    return(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 (30 points): Fill-in code for normalizing features, and the above two functions to implement k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2 (20 points): Run your k-NN implementation on the test data set. Use k=5. Compute accuracy, recall and precision of the test data set (do not use python library functions to compute these). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1.]\n",
      "156 171 0.9122807017543859\n",
      "accuracy is 91.228070 percenatge\n"
     ]
    }
   ],
   "source": [
    "# problem 2 solution:(TP + TN)/float(TP + TN + FP + FN))=156/171\n",
    "#tp=118,tn=38,fp=1,fn=14\n",
    "from sklearn import metrics\n",
    "yprediction=knn_predict(Xtr, Ytr, Xts,k=5)\n",
    "print(yprediction)\n",
    "#accuracy=0.9122\n",
    "#print(metrics.accuracy_score(Yts, yprediction))\n",
    "test_shape=Xts.shape[0]\n",
    "correct = np.sum(yprediction == Yts)\n",
    "accuracy = float(correct)/test_shape\n",
    "print(correct,test_shape, accuracy)\n",
    "print(\"accuracy is %f percenatge\"%(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "38\n",
      "1\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "TP=np.sum([(yprediction==1) & (1==Yts)])\n",
    "print(TP)\n",
    "TN=np.sum([(yprediction==0) & (0==Yts)])\n",
    "print(TN)\n",
    "FP=np.sum([(yprediction==1) & (0==Yts)])\n",
    "print(FP)\n",
    "FN=np.sum([(yprediction==0) & (1==Yts)])\n",
    "print(FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8939393939393939\n",
      "recall is 89.393939 percenatge\n"
     ]
    }
   ],
   "source": [
    "# problem 2 solution-recall=TP/(TP + FN)=118/118+14=0.8939\n",
    "#print(metrics.recall_score(Yts, yprediction))\n",
    "print(TP/float(TP + FN))\n",
    "print(\"recall is %f percenatge\"%((TP/float(TP + FN))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9915966386554622\n",
      "precision is 99.159664 percenatge\n"
     ]
    }
   ],
   "source": [
    "# problem 2 solution-precision=TP /(TP + FP)=0.9915\n",
    "#print(metrics.confusion_matrix(Yts, yprediction))\n",
    "#print(metrics.precision_score(Yts, yprediction))\n",
    "print(TP /float(TP + FP))\n",
    "print(\"precision is %f percenatge\"%((TP /float(TP + FP))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Priblem 3 (30 points): Now we will implement 5-fold cross-validation to find the best value of $k$. And then using that value of $k$, re-run k-NN on the test data set. (This is adapted from a past Stanford cs231n assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, accuracy = 0.787500\n",
      "k = 1, accuracy = 0.787500\n",
      "k = 1, accuracy = 0.875000\n",
      "k = 1, accuracy = 0.873418\n",
      "k = 1, accuracy = 0.898734\n",
      "mean , k=1 is 0.844430\n",
      "k = 3, accuracy = 0.787500\n",
      "k = 3, accuracy = 0.812500\n",
      "k = 3, accuracy = 0.887500\n",
      "k = 3, accuracy = 0.911392\n",
      "k = 3, accuracy = 0.886076\n",
      "mean , k=3 is 0.856994\n",
      "k = 5, accuracy = 0.825000\n",
      "k = 5, accuracy = 0.837500\n",
      "k = 5, accuracy = 0.900000\n",
      "k = 5, accuracy = 0.936709\n",
      "k = 5, accuracy = 0.911392\n",
      "mean , k=5 is 0.882120\n",
      "k = 7, accuracy = 0.837500\n",
      "k = 7, accuracy = 0.837500\n",
      "k = 7, accuracy = 0.875000\n",
      "k = 7, accuracy = 0.949367\n",
      "k = 7, accuracy = 0.924051\n",
      "mean , k=7 is 0.884684\n",
      "k = 9, accuracy = 0.850000\n",
      "k = 9, accuracy = 0.837500\n",
      "k = 9, accuracy = 0.900000\n",
      "k = 9, accuracy = 0.924051\n",
      "k = 9, accuracy = 0.936709\n",
      "mean , k=9 is 0.889652\n",
      "k = 11, accuracy = 0.850000\n",
      "k = 11, accuracy = 0.825000\n",
      "k = 11, accuracy = 0.912500\n",
      "k = 11, accuracy = 0.924051\n",
      "k = 11, accuracy = 0.936709\n",
      "mean , k=11 is 0.889652\n",
      "k = 13, accuracy = 0.887500\n",
      "k = 13, accuracy = 0.825000\n",
      "k = 13, accuracy = 0.912500\n",
      "k = 13, accuracy = 0.924051\n",
      "k = 13, accuracy = 0.911392\n",
      "mean , k=13 is 0.892089\n",
      "k = 15, accuracy = 0.875000\n",
      "k = 15, accuracy = 0.837500\n",
      "k = 15, accuracy = 0.925000\n",
      "k = 15, accuracy = 0.924051\n",
      "k = 15, accuracy = 0.911392\n",
      "mean , k=15 is 0.894589\n",
      "k = 20, accuracy = 0.862500\n",
      "k = 20, accuracy = 0.850000\n",
      "k = 20, accuracy = 0.925000\n",
      "k = 20, accuracy = 0.911392\n",
      "k = 20, accuracy = 0.924051\n",
      "mean , k=20 is 0.894589\n",
      "k = 30, accuracy = 0.850000\n",
      "k = 30, accuracy = 0.837500\n",
      "k = 30, accuracy = 0.950000\n",
      "k = 30, accuracy = 0.936709\n",
      "k = 30, accuracy = 0.936709\n",
      "mean , k=30 is 0.902184\n",
      "k = 40, accuracy = 0.825000\n",
      "k = 40, accuracy = 0.850000\n",
      "k = 40, accuracy = 0.937500\n",
      "k = 40, accuracy = 0.924051\n",
      "k = 40, accuracy = 0.949367\n",
      "mean , k=40 is 0.897184\n",
      "k = 50, accuracy = 0.825000\n",
      "k = 50, accuracy = 0.837500\n",
      "k = 50, accuracy = 0.937500\n",
      "k = 50, accuracy = 0.924051\n",
      "k = 50, accuracy = 0.974684\n",
      "mean , k=50 is 0.899747\n",
      "k = 75, accuracy = 0.825000\n",
      "k = 75, accuracy = 0.850000\n",
      "k = 75, accuracy = 0.937500\n",
      "k = 75, accuracy = 0.924051\n",
      "k = 75, accuracy = 0.962025\n",
      "mean , k=75 is 0.899715\n",
      "k = 100, accuracy = 0.800000\n",
      "k = 100, accuracy = 0.862500\n",
      "k = 100, accuracy = 0.925000\n",
      "k = 100, accuracy = 0.924051\n",
      "k = 100, accuracy = 0.962025\n",
      "mean , k=100 is 0.894715\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 7, 9, 11, 13, 15, 20, 30, 40, 50, 75, 100]\n",
    "\n",
    "Xtrfolds = []\n",
    "Ytrfolds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "#np.array_split: Split array into multiple sub-arrays size=num_folds=5.\n",
    "Xtrfolds = np.array_split(Xtr, num_folds)\n",
    "Ytrfolds = np.array_split(Ytr, num_folds)\n",
    "#Ytrfolds.shape=5,\n",
    "#print(Ytrfolds.shape)\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "#create empty list for all k choices\n",
    "for k in k_choices:\n",
    "    k_to_accuracies[k] = []\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of k in the k_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "for k in k_choices:\n",
    "    for i in range(num_folds):\n",
    "        #Use fold 1 as the testing set and the union of the other folds as the training set.\n",
    "        #np.vstack : Stack arrays in sequence vertically (row wise)\n",
    "        Xtr_cv = np.vstack(Xtrfolds[0:i]+Xtrfolds[i+1:])\n",
    "        #print(Xtr_cv)\n",
    "        #np.hstack:Stack arrays in sequence horizontally (column wise).\n",
    "        Ytr_cv = np.hstack(Ytrfolds[0:i] + Ytrfolds[i+1:])\n",
    "        \n",
    "        #test set\n",
    "        Xts_cv = Xtrfolds[i]\n",
    "        #print(Xts_cv.shape)\n",
    "        Yts_cv = Ytrfolds[i]\n",
    "        #call knn predict \n",
    "        yprediction_cv=knn_predict(Xtr_cv, Ytr_cv, Xts_cv,k)\n",
    "        #yprediction_cv\n",
    "        \n",
    "        #accuracy for each CV fold\n",
    "        correct_cv = np.sum(Yts_cv == yprediction_cv)\n",
    "        accuracy_cv = (float)(correct_cv)/Yts_cv.shape[0]\n",
    "        k_to_accuracies[k].append(accuracy_cv)  \n",
    "        \n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))\n",
    "    print('mean , k=%d is %f' % (k, np.mean(k_to_accuracies[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1f145898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9021835443037975\n"
     ]
    }
   ],
   "source": [
    "#k = 30, accuracy = 0.9021(taking average)\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "print(accuracies_mean.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4 (20 points): Based on the cross-validation results above, choose the best value for $k$. Repeat problem 2 with this $k$ (using the entire training data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157 171 0.9181286549707602\n"
     ]
    }
   ],
   "source": [
    "#problem 4 solution-accuracy\n",
    "#mean for k=5 is 0.882120\n",
    "#mean for k=15 is 0.894589\n",
    "#mean for k=30 is 0.902184\n",
    "#best_value_K=30\n",
    "yprediction_best_k=knn_predict(Xtr, Ytr, Xts,k=30)\n",
    "\n",
    "#print(metrics.accuracy_score(Yts, yprediction))\n",
    "test_shape=Xts.shape[0]\n",
    "correct = np.sum(yprediction_best_k == Yts)\n",
    "accuracy = float(correct)/test_shape\n",
    "print(correct, test_shape, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n",
      "36\n",
      "3\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "TP1=np.sum([(yprediction_best_k==1) & (1==Yts)])\n",
    "print(TP1)\n",
    "TN1=np.sum([(yprediction_best_k==0) & (0==Yts)])\n",
    "print(TN1)\n",
    "FP1=np.sum([(yprediction_best_k==1) & (0==Yts)])\n",
    "print(FP1)\n",
    "FN1=np.sum([(yprediction_best_k==0) & (1==Yts)])\n",
    "print(FN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "recall is 91.666667 percenatge\n"
     ]
    }
   ],
   "source": [
    "# problem 4 solution-recall=TP/(TP + FN)\n",
    "#print(metrics.recall_score(Yts, yprediction))\n",
    "print(TP1/float(TP1 + FN1))\n",
    "print(\"recall is %f percenatge\"%((TP1/float(TP1 + FN1))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758064516129032\n",
      "precision is 97.580645 percenatge\n"
     ]
    }
   ],
   "source": [
    "# problem 4 solution-precision=TP /(TP + FP)\n",
    "print(TP1 /float(TP1 + FP1))\n",
    "print(\"precision is %f percenatge\"%((TP1 /float(TP1 + FP1))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: these extra credit problems are optional and only increase your score marginally. \n",
    "\n",
    "Extra Credit Problem 1 (5 points): Plot decision boundaries for the best $k$, similar to how it is done here:\n",
    "http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
    "\n",
    "Extra Credit Problem 2 (5 points): In problem 1 above, re-write the compute_dist_mat() function with no loops. That may seem non-intuitive, but it is possible to compute the L2 distances using matrix operations (matrix multiplication, addition, etc.) without explicitly doing the double for loop. The advantage of using matrix operations is that they are highly optimized and enable \"vectorization\", and for such computations can give 10-100x speed improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Credit Problem 2\n",
    "#(a-b)**2=a**2+b**2-2*a*b\n",
    "def compute_dist_mat_extraCredit(Xts, Xtr):\n",
    "    XtsSSqr= np.sum(np.square(Xts),axis=1);\n",
    "    XtrSSqr = np.sum(np.square(Xtr),axis=1);\n",
    "    mul = np.dot(Xts,Xtr.T);\n",
    "    distance = np.sqrt(XtsSSqr[:,np.newaxis]+XtrSSqr-2*mul)\n",
    "    return(distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
